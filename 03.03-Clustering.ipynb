{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering Concept:\n",
    "**Concept**:\n",
    "\n",
    "**Definition**: Clustering is a type of unsupervised learning where the goal is to group similar data points together based on certain features or characteristics.\n",
    "Objective: The objective is to discover inherent structures or patterns in the data without prior knowledge of the groups.\n",
    "Analogy:\n",
    "\n",
    "**Imagine a Library:** Think of a library with a large collection of books. If you were to organize these books without any labels or categories, you might naturally group them based on topics, genres, or authors. Each group would represent a cluster of books with similar content.\n",
    "\n",
    "### **Key Aspects:**\n",
    "\n",
    "**Similarity Metric**:\n",
    "\n",
    "Clustering relies on a similarity metric to measure how alike or different data points are. Common metrics include Euclidean distance or cosine similarity.\n",
    "Unsupervised Nature:\n",
    "\n",
    "Clustering is unsupervised because it doesn't have predefined categories; the algorithm discovers patterns on its own.\n",
    "\n",
    "## K-Means Algorithm:\n",
    "**Concept**:\n",
    "\n",
    "- **Definition**: K-Means is a popular clustering algorithm that partitions data into K clusters, where each data point belongs to the cluster with the nearest mean (centroid).\n",
    "Objective: Minimize the within-cluster sum of squares, making data points within a cluster as similar as possible.\n",
    "\n",
    "**Analogy**:\n",
    "\n",
    "- **Organizing Party Guests**:\n",
    "Imagine you're organizing a party, and you want to group guests based on their interests. K-Means would be like placing guests into K groups so that people within each group share similar interests.\n",
    "Steps of K-Means:\n",
    "\n",
    "**Initialization**:\n",
    "\n",
    "Choose K initial centroids randomly (representing the initial cluster centers).\n",
    "\n",
    "**Assignment**:\n",
    "\n",
    "Assign each data point to the cluster whose centroid is the closest.\n",
    "Update Centroids:\n",
    "\n",
    "Recalculate the centroids based on the mean of data points in each cluster.\n",
    "\n",
    "\n",
    "**Repeat**:\n",
    "\n",
    "Repeat the assignment and update steps until convergence (when the centroids stabilize or don't change significantly).\n",
    "\n",
    "### **Key Aspects:**\n",
    "\n",
    "- **K Selection:**\n",
    "\n",
    "Choosing the right value for K is crucial. It depends on the nature of the data and the desired level of granularity.\n",
    "Sensitivity to Initialization:\n",
    "\n",
    "The performance of K-Means can be sensitive to the initial choice of centroids. Multiple initializations and choosing the best result can mitigate this.\n",
    "\n",
    "- **Limitations**:\n",
    "\n",
    "K-Means assumes spherical clusters and struggles with non-linear shapes or varying cluster sizes.\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juancml/mambaforge/envs/sklearn-env/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KMeans(n_clusters=2, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KMeans</label><div class=\"sk-toggleable__content\"><pre>KMeans(n_clusters=2, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KMeans(n_clusters=2, random_state=42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see if Kmeans is able to distinguish \n",
    "# between malignant an benign \n",
    "\n",
    "X = data.data\n",
    "# Algorithm for 2 clusters knowing there's 2 classes\n",
    "kmeans = KMeans(n_clusters=2, random_state=42)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8541300527240774"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# How well K-Means did the partition\n",
    "(kmeans.labels_ == data.target).sum() / len(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happen if i first apply PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/juancml/mambaforge/envs/sklearn-env/lib/python3.12/site-packages/sklearn/cluster/_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "pca = PCA(n_components=2).fit(X)\n",
    "X_red = pca.transform(X)\n",
    "\n",
    "kmeans2 = KMeans(n_clusters=2, random_state=42).fit(X_red)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8541300527240774"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(kmeans.labels_ == data.target).sum() / len(kmeans.labels_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nothing :/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "### Agglomerative Clustering:\n",
    "\n",
    "**Concept:**\n",
    "- **Definition:** Agglomerative Clustering is a hierarchical clustering algorithm that starts with individual data points as separate clusters and iteratively merges the closest clusters until only one cluster remains.\n",
    "- **Objective:** The algorithm creates a hierarchy of clusters, revealing relationships at different levels of granularity.\n",
    "\n",
    "**Analogy:**\n",
    "- **Family Tree:**\n",
    "  - Imagine constructing a family tree. At the beginning, each person is a separate cluster (like an individual data point). As you discover relationships, you merge individuals into families, and families into larger branches, forming a hierarchical structure.\n",
    "\n",
    "**Steps of Agglomerative Clustering:**\n",
    "1. **Individual Data Points:**\n",
    "   - Start with each data point as a separate cluster.\n",
    "\n",
    "2. **Merge Closest Clusters:**\n",
    "   - Iteratively merge the two closest clusters based on a specified distance metric.\n",
    "\n",
    "3. **Hierarchy Formation:**\n",
    "   - Continue merging until all data points belong to a single cluster, forming a hierarchy.\n",
    "\n",
    "**Key Aspects:**\n",
    "1. **Dendrogram:**\n",
    "   - The result is often visualized as a dendrogram, a tree-like diagram showing the hierarchy of clusters.\n",
    "\n",
    "2. **Linkage Criteria:**\n",
    "   - Different linkage criteria (e.g., ward, complete, average) determine how the distance between clusters is calculated.\n",
    "\n",
    "---\n",
    "\n",
    "### DBSCAN (Density-Based Spatial Clustering of Applications with Noise):\n",
    "\n",
    "**Concept:**\n",
    "- **Definition:** DBSCAN is a density-based clustering algorithm that groups together data points that are close to each other and have a sufficient number of neighbors, while marking data points in less dense regions as noise.\n",
    "- **Objective:** Identify clusters of varying shapes and densities.\n",
    "\n",
    "**Analogy:**\n",
    "- **People Gathering:**\n",
    "  - Imagine people gathering in a park. DBSCAN would identify groups of people standing close to each other as clusters, regardless of the overall park's size. People sitting alone might be considered noise.\n",
    "\n",
    "**Steps of DBSCAN:**\n",
    "1. **Core Points:**\n",
    "   - Identify core points that have a minimum number of neighbors within a specified radius.\n",
    "\n",
    "2. **Expand Clusters:**\n",
    "   - Expand clusters by adding reachable points to the core points, forming dense regions.\n",
    "\n",
    "3. **Noise Detection:**\n",
    "   - Points that are not part of any cluster or have insufficient neighbors are considered noise.\n",
    "\n",
    "**Key Aspects:**\n",
    "1. **Flexibility with Cluster Shapes:**\n",
    "   - DBSCAN is effective at identifying clusters of arbitrary shapes and is not sensitive to the spherical assumption.\n",
    "\n",
    "2. **Parameter Selection:**\n",
    "   - Parameters include the radius (epsilon) and the minimum number of points required to form a dense region (minPts).\n",
    "\n",
    "3. **Noise Handling:**\n",
    "   - DBSCAN can handle noise and outliers effectively, marking them as separate entities.\n",
    "\n",
    "**Example:**\n",
    "- **Monitoring Network Anomalies:**\n",
    "  - Consider monitoring network traffic. DBSCAN could identify clusters of usual activity and mark unusual patterns as noise, potentially indicating anomalies or security threats."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying Agglomerative clusteering and DBSCAN on data set for ilustrative purposes (i'm just experimenting). \n",
    "\n",
    "I'm curious about what happend if we already know how data is divided and apply unsupervised clustering. \n",
    "\n",
    "How accurately these models can separate classes? ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for ward linkage: 0.22144112478031636\n",
      "Accuracy for complete linkage: 0.6625659050966608\n",
      "Accuracy for average linkage: 0.6625659050966608\n",
      "Accuracy for single linkage: 0.37082601054481545\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "# Different linkage criterion should have different accuracy results\n",
    "linkages = ['ward', 'complete', 'average', 'single']\n",
    "for linkage in linkages:\n",
    "# Labels must be instantiated\n",
    "    clt = AgglomerativeClustering(n_clusters=2, \n",
    "                                  linkage= linkage,\n",
    "                                  )\n",
    "                                # Already knowing there's two classes\n",
    "    labels = clt.fit_predict(X)\n",
    "    \n",
    "    acc = (labels == data.target).sum() / len(labels)\n",
    "    print(f'Accuracy for {linkage} linkage: {acc}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- What if i don't specify the number of groups? \n",
    "\n",
    "- Will DBSCAN identify malignant and benignant?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "# Default parametters \n",
    "# eps = 0.5, min_samples = 5\n",
    "dbscan = DBSCAN()\n",
    "clusters = dbscan.fit_predict(X)\n",
    "\n",
    "print(np.unique(clusters))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only detected noise :/ ...\n",
    "\n",
    "Apparently i didn't scaled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.09706398, -2.07333501,  1.26993369, ...,  2.29607613,\n",
       "         2.75062224,  1.93701461],\n",
       "       [ 1.82982061, -0.35363241,  1.68595471, ...,  1.0870843 ,\n",
       "        -0.24388967,  0.28118999],\n",
       "       [ 1.57988811,  0.45618695,  1.56650313, ...,  1.95500035,\n",
       "         1.152255  ,  0.20139121],\n",
       "       ...,\n",
       "       [ 0.70228425,  2.0455738 ,  0.67267578, ...,  0.41406869,\n",
       "        -1.10454895, -0.31840916],\n",
       "       [ 1.83834103,  2.33645719,  1.98252415, ...,  2.28998549,\n",
       "         1.91908301,  2.21963528],\n",
       "       [-1.80840125,  1.22179204, -1.81438851, ..., -1.74506282,\n",
       "        -0.04813821, -0.75120669]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdr = StandardScaler()\n",
    "X_scaled = stdr.fit_transform(X)\n",
    "\n",
    "\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple combination of parametters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min_samples: 2 - eps: 0.5 -> Clusters: [-1]\n",
      "min_samples: 2 - eps: 1 -> Clusters: [-1]\n",
      "min_samples: 2 - eps: 1.5 -> Clusters: [-1  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "min_samples: 2 - eps: 2 -> Clusters: [-1  0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19]\n",
      "min_samples: 2 - eps: 3 -> Clusters: [-1  0  1  2  3  4  5  6]\n",
      "\n",
      "\n",
      "min_samples: 3 - eps: 0.5 -> Clusters: [-1]\n",
      "min_samples: 3 - eps: 1 -> Clusters: [-1]\n",
      "min_samples: 3 - eps: 1.5 -> Clusters: [-1  0  1  2  3  4  5]\n",
      "min_samples: 3 - eps: 2 -> Clusters: [-1  0  1  2  3  4  5  6]\n",
      "min_samples: 3 - eps: 3 -> Clusters: [-1  0  1]\n",
      "\n",
      "\n",
      "min_samples: 5 - eps: 0.5 -> Clusters: [-1]\n",
      "min_samples: 5 - eps: 1 -> Clusters: [-1]\n",
      "min_samples: 5 - eps: 1.5 -> Clusters: [-1  0]\n",
      "min_samples: 5 - eps: 2 -> Clusters: [-1  0  1  2  3]\n",
      "min_samples: 5 - eps: 3 -> Clusters: [-1  0]\n",
      "\n",
      "\n",
      "min_samples: 7 - eps: 0.5 -> Clusters: [-1]\n",
      "min_samples: 7 - eps: 1 -> Clusters: [-1]\n",
      "min_samples: 7 - eps: 1.5 -> Clusters: [-1  0]\n",
      "min_samples: 7 - eps: 2 -> Clusters: [-1  0  1]\n",
      "min_samples: 7 - eps: 3 -> Clusters: [-1  0]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "samples = [2, 3, 5, 7]\n",
    "radius = [0.5, 1, 1.5, 2, 3]\n",
    "\n",
    "for min_sample in samples:\n",
    "    for eps in radius:\n",
    "        dbscan = DBSCAN(min_samples=min_sample, eps=eps)\n",
    "        clusters = dbscan.fit_predict(X_scaled)\n",
    "        print(f'min_samples: {min_sample} - eps: {eps} -> Clusters: {np.unique(clusters)}')\n",
    "    print('\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sklearn-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
